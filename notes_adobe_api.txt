To detect the main title:
. Evaluate the path "//Document/Title".

To identify chapters and sections:
. Evaluate the path "//Document/H1".
. Note that with each new path containing "H1" we have the increment of the sections "//Document/Sect[3]/H1".
. All the other paragraphs within this section, regardless of "Page", represent their respective bodies.
. IMPORTANT: detect "Path" of H1 or H2 sections "//Document/H1[14]" whose "Text" contains the word "References" and delete everything.

To identify an abstract:
. Evaluate whether it is a paragraph "//Document/P[8]";
. Check for the keyword "Keywords: gratitude, app...lationship maintenance" at the beginning of the sentence, which characterizes the immediately preceding paragraph as an abstract.

To identify footnotes:
. In the most direct way, simply identify the path "//Document/Footnote".
. In the sequence of a paragraph "//Document/P[7]" or "//Document/P[20]/ParagraphSpan[2]", identify the decrease in font "TextSize".
. As long as the font remains the same, the footnote has several paragraphs.
. Returning the paragraph to its normal font means that the paragraph belongs to the original "H1" chapter/section.
. Discard footnotes "//Document/Footnote[4]" that are preceded by a table, as they will be discarded.

To identify and delete the footer:
. Evaluate the font size "TextSize".
. If it is less than or equal to 2 points below the text font (small font), then it can be considered a footer.

. IMPORTANT: pay attention to the fact that a footnote, when referenced by a number within a common text, will characterize the entire paragraph with the smallest possible font, creating a false positive "footer" to be eliminated.

To detect author(s) (this part is not yet very well defined):
. Evaluate paragraph "//Document/P[10]".
. Evaluate font change "TextSize" (non-standard size).
. Evaluate short texts preceding the abstract (for scientific papers).
. Path type Paragraph (P) beginning with "by" or that has a one line text with the word 'author' inside: "By (<https://www.theatlantic.com/author/arthur-c-brooks/>)(<https://www.theatlantic.com/author/arthur-c-brooks/>)Arthur C. Brooks "

To detect bodies with lists (topics):
. Evaluate whether the LI option "//Document/Sect[4]/Sect/L/LI[14]/..." exists within a paragraph.
. Evaluate the marker for each item in this list containing LBL "//Document/Sect[4]/Sect/L/LI[14]/Lbl".
. Evaluate each item in the list that follows the bookmark and has LBODY "//Document/Sect[4]/Sect/L/LI[14]/LBody".

To identify page numbers consistent with titles, chapters, sections and their respective bodies:
. Evaluate the "Page" key, which is at the same level as "Path".

To extract bodies from page elements:
. Search for paragraphs such as "//Document/P[20]/ParagraphSpan[2]" or "//Document/P[10]".
. You can use the Sub "//Document/P[44]/Sub" or "//Document/P[44]/Sub[2]" for sections with table names that will be discarded.

Delete keys of type:
. Aside "//Document/Sect[2]/Aside/P".
. Reference "//Document/P[14]/Reference".
. StyleSpan "//Document/P/StyleSpan".
. Figure "//Document/Sect/Figure" or "//Document/Figure".
. Table "//Document/Sect[4]/Sect/Table".
    . In addition to the table layout "//Document/Sect[4]/Sect/Table/TR/TH".
    . "//Document/Sect[4]/Sect/Table/TR/TH/P".
    . "//Document/Sect[4]/Sect/Table/TR[5]/TD[2]"
. Sections such as "version", "extended_metadata" and "pages" (preserve only "elements").

To detect important dates in a scientific paper:
. Evaluate the presence of "Path" and "Text" containing words like Received, Revision and Accepted combined with dates to detect the dates in the document.
. The following variables are usually found on the last page of the document, after the references:
    . Path "//Document/P[206]/Sub"
    . Text "Received January 6, 2011"
    . Path "//Document/P[206]/Sub[2]"
    . Text "Revision received April 18, 2012"
    . Path "//Document/P[207]"
    . Text "Accepted April 23, 2012"

=========
Conclusion - WCO-92:
According to the techniques evaluated in the PDF parsing process, the use of several combined techniques is noted, namely:
1. Considering the different categories of PDFs (books, articles and scientific papers), we must distinguish between them before choosing the tools.
2. If the books are published directly by the publishers, they will certainly come with their own metadata, including authors, chapters, sections, date of publication and content. This makes the use of the Pymupdf library sufficient.
3. For scientific papers that follow stricter formatting standards, we can use GrobId.
4. For PDF articles created from the web that don't follow strict standards, or even books generated from scans of works that weren't generated with their respective metadata, we need to use a combination of these. A formula that can be applied, in order of priority, would be Pymupdf, followed by GrobId and, if the file is less than 1MB, Adobe Parsing API.
5. The latter can even be applied to all categories (books, articles and scientific papers) that don't have metadata, as it extracts information and groups it into JSON-structured tags, which I've mapped in the comment https://bairesdev.atlassian.net/browse/WCO-92?focusedCommentId=3214579.

============
Conclusion - WCO-93:

The template to be used for "Clean up raw data - remove footers, headers, images..." will be as follows:

1. Within the respective Python libraries (Pymupdf, GrobId), we will load only the elements necessary for the composition of the requested items, such as authors, titles, body, etc.

2. If you are using the Adobe Parsing API model, follow the steps below, collecting only the elements you are interested in and excluding other tags from the resulting JSON to make the file smaller:

To detect bodies with lists (topics):
. Evaluate whether the LI option "//Document/Sect[4]/Sect/L/LI[14]/..." exists within a paragraph.
. Evaluate the marker for each item in this list containing LBL "//Document/Sect[4]/Sect/L/LI[14]/Lbl".
. Evaluate each item in the list that follows the bookmark and has LBODY "//Document/Sect[4]/Sect/L/LI[14]/LBody".

To extract bodies from page elements:
. Search for paragraphs such as "//Document/P[20]/ParagraphSpan[2]" or "//Document/P[10]".
. You can use the Sub "//Document/P[44]/Sub" or "//Document/P[44]/Sub[2]" for sections with table names that will be discarded.

Delete keys of type:
. Aside "//Document/Sect[2]/Aside/P".
. Reference "//Document/P[14]/Reference".
. StyleSpan "//Document/P/StyleSpan".
. Figure "//Document/Sect/Figure" or "//Document/Figure".
. Table "//Document/Sect[4]/Sect/Table".
    . In addition to the table layout "//Document/Sect[4]/Sect/Table/TR/TH".
    . "//Document/Sect[4]/Sect/Table/TR/TH/P".
    . "//Document/Sect[4]/Sect/Table/TR[5]/TD[2]"
. Sections such as "version", "extended_metadata" and "pages" (preserve only "elements").


============================
    buffer_pdf = fitz.open()
    buffer_pdf.insert_pdf(doc, from_page=page_num, to_page=page_num)
nesse caso buffer_pdf seria o pdf com as paginas que vc quer... doc é o pdf que foi aberto usando fitz.open() (fitz é o pymupdf).